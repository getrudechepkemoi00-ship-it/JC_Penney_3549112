{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding\n",
    "\n",
    "JCPenney is a large retail company that sells a wide range of products such as clothing, beauty products, home goods, and accessories. They get these products from top brands and usually sell these products at discounted prices. \n",
    "\n",
    "The aim of these analysis is to understand customer behaviour, how they interact with products, how satisfied they are, and which products or brands they prefer. In this analysis I will look at product ratings, review patterns, customer demographics, and discount levels to see what influences satisfaction, which products perform best, and whether discounts actually affect customer feedback.\n",
    "\n",
    "The important data for this analysis, is username, customer id, customer age (we will calculate this from DOB), state, prices, product categories, average product ratings, and reviews, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding & preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>DOB</th>\n",
       "      <th>State</th>\n",
       "      <th>Reviewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkpn1412</td>\n",
       "      <td>31.07.1983</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>[cea76118f6a9110a893de2b7654319c0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gqjs4414</td>\n",
       "      <td>27.07.1998</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>[fa04fe6c0dd5189f54fe600838da43d3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eehe1434</td>\n",
       "      <td>08.08.1950</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hkxj1334</td>\n",
       "      <td>03.08.1969</td>\n",
       "      <td>Florida</td>\n",
       "      <td>[f129b1803f447c2b1ce43508fb822810, 3b0c9bc0be6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jjbd1412</td>\n",
       "      <td>26.07.2001</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Username         DOB          State  \\\n",
       "0  bkpn1412  31.07.1983         Oregon   \n",
       "1  gqjs4414  27.07.1998  Massachusetts   \n",
       "2  eehe1434  08.08.1950          Idaho   \n",
       "3  hkxj1334  03.08.1969        Florida   \n",
       "4  jjbd1412  26.07.2001        Georgia   \n",
       "\n",
       "                                            Reviewed  \n",
       "0                 [cea76118f6a9110a893de2b7654319c0]  \n",
       "1                 [fa04fe6c0dd5189f54fe600838da43d3]  \n",
       "2                                                 []  \n",
       "3  [f129b1803f447c2b1ce43508fb822810, 3b0c9bc0be6...  \n",
       "4                                                 []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewers shape: (5000, 4)\n",
      "reviewers dtypes:\n",
      " Username    object\n",
      "DOB         object\n",
      "State       object\n",
      "Reviewed    object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uniq_id</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sku</th>\n",
       "      <td>pp5006380337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_title</th>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>You'll return to our Alfred Dunner pull-on cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>list_price</th>\n",
       "      <td>41.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sale_price</th>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>alfred dunner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_tree</th>\n",
       "      <td>jcpenney|women|alfred dunner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_product_rating</th>\n",
       "      <td>2.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_url</th>\n",
       "      <td>http://www.jcpenney.com/alfred-dunner-essentia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_image_urls</th>\n",
       "      <td>http://s7d9.scene7.com/is/image/JCPenney/DP122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>Alfred Dunner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_number_reviews</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reviews</th>\n",
       "      <td>[{'User': 'fsdv4141', 'Review': 'You never hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bought With</th>\n",
       "      <td>[898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        0\n",
       "uniq_id                                  b6c0b6bea69c722939585baeac73c13d\n",
       "sku                                                          pp5006380337\n",
       "name_title                    Alfred Dunner® Essential Pull On Capri Pant\n",
       "description             You'll return to our Alfred Dunner pull-on cap...\n",
       "list_price                                                          41.09\n",
       "sale_price                                                          24.16\n",
       "category                                                    alfred dunner\n",
       "category_tree                                jcpenney|women|alfred dunner\n",
       "average_product_rating                                              2.625\n",
       "product_url             http://www.jcpenney.com/alfred-dunner-essentia...\n",
       "product_image_urls      http://s7d9.scene7.com/is/image/JCPenney/DP122...\n",
       "brand                                                       Alfred Dunner\n",
       "total_number_reviews                                                    8\n",
       "Reviews                 [{'User': 'fsdv4141', 'Review': 'You never hav...\n",
       "Bought With             [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products shape: (7982, 15)\n",
      "products dtypes:\n",
      " uniq_id                    object\n",
      "sku                        object\n",
      "name_title                 object\n",
      "description                object\n",
      "list_price                 object\n",
      "sale_price                 object\n",
      "category                   object\n",
      "category_tree              object\n",
      "average_product_rating    float64\n",
      "product_url                object\n",
      "product_image_urls         object\n",
      "brand                      object\n",
      "total_number_reviews        int64\n",
      "Reviews                    object\n",
      "Bought With                object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq_id</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Av_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>2.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93e5272c51d8cce02597e3ce67b7ad0a</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>013e320f2f2ec0cf5b3ff5418d688528</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>2.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>505e6633d81f2cb7400c0cfa0394c427</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>3.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d969a8542122e1331e304b09f81a83f6</td>\n",
       "      <td>pp5006380337</td>\n",
       "      <td>Alfred Dunner® Essential Pull On Capri Pant</td>\n",
       "      <td>Youll return to our Alfred Dunner pull-on capr...</td>\n",
       "      <td>41.09</td>\n",
       "      <td>3.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Uniq_id           SKU  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
       "1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
       "2  013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
       "3  505e6633d81f2cb7400c0cfa0394c427  pp5006380337   \n",
       "4  d969a8542122e1331e304b09f81a83f6  pp5006380337   \n",
       "\n",
       "                                          Name  \\\n",
       "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "1  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "2  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "3  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "4  Alfred Dunner® Essential Pull On Capri Pant   \n",
       "\n",
       "                                         Description  Price  Av_Score  \n",
       "0  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
       "1  Youll return to our Alfred Dunner pull-on capr...  41.09     3.000  \n",
       "2  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
       "3  Youll return to our Alfred Dunner pull-on capr...  41.09     3.500  \n",
       "4  Youll return to our Alfred Dunner pull-on capr...  41.09     3.125  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products_csv shape: (7982, 6)\n",
      "products_csv dtypes:\n",
      " Uniq_id         object\n",
      "SKU             object\n",
      "Name            object\n",
      "Description     object\n",
      "Price          float64\n",
      "Av_Score       float64\n",
      "dtype: object\n",
      "products_csv missing values:\n",
      " Uniq_id           0\n",
      "SKU              67\n",
      "Name              0\n",
      "Description     543\n",
      "Price          2166\n",
      "Av_Score          0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Uniq_id</th>\n",
       "      <th>Username</th>\n",
       "      <th>Score</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>fsdv4141</td>\n",
       "      <td>2</td>\n",
       "      <td>You never have to worry about the fit...Alfred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>krpz1113</td>\n",
       "      <td>1</td>\n",
       "      <td>Good quality fabric. Perfect fit. Washed very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>mbmg3241</td>\n",
       "      <td>2</td>\n",
       "      <td>I do not normally wear pants or capris that ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>zeqg1222</td>\n",
       "      <td>0</td>\n",
       "      <td>I love these capris! They fit true to size and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b6c0b6bea69c722939585baeac73c13d</td>\n",
       "      <td>nvfn3212</td>\n",
       "      <td>3</td>\n",
       "      <td>This product is very comfortable and the fabri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Uniq_id  Username  Score  \\\n",
       "0  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
       "1  b6c0b6bea69c722939585baeac73c13d  krpz1113      1   \n",
       "2  b6c0b6bea69c722939585baeac73c13d  mbmg3241      2   \n",
       "3  b6c0b6bea69c722939585baeac73c13d  zeqg1222      0   \n",
       "4  b6c0b6bea69c722939585baeac73c13d  nvfn3212      3   \n",
       "\n",
       "                                              Review  \n",
       "0  You never have to worry about the fit...Alfred...  \n",
       "1  Good quality fabric. Perfect fit. Washed very ...  \n",
       "2  I do not normally wear pants or capris that ha...  \n",
       "3  I love these capris! They fit true to size and...  \n",
       "4  This product is very comfortable and the fabri...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews_csv shape: (39063, 4)\n",
      "reviews_csv dtypes:\n",
      " Uniq_id     object\n",
      "Username    object\n",
      "Score        int64\n",
      "Review      object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>DOB</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bkpn1412</td>\n",
       "      <td>31.07.1983</td>\n",
       "      <td>Oregon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gqjs4414</td>\n",
       "      <td>27.07.1998</td>\n",
       "      <td>Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eehe1434</td>\n",
       "      <td>08.08.1950</td>\n",
       "      <td>Idaho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hkxj1334</td>\n",
       "      <td>03.08.1969</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jjbd1412</td>\n",
       "      <td>26.07.2001</td>\n",
       "      <td>Georgia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Username         DOB          State\n",
       "0  bkpn1412  31.07.1983         Oregon\n",
       "1  gqjs4414  27.07.1998  Massachusetts\n",
       "2  eehe1434  08.08.1950          Idaho\n",
       "3  hkxj1334  03.08.1969        Florida\n",
       "4  jjbd1412  26.07.2001        Georgia"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_csv shape: (5000, 3)\n",
      "users_csv dtypes:\n",
      " Username    object\n",
      "DOB         object\n",
      "State       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data Inspection and understanding\n",
    "import pandas as pd\n",
    "# JC Penney Reviewers (JSON)\n",
    "reviewers = pd.read_json(\"jcpenney_reviewers.json\", lines=True)\n",
    "display(reviewers.head())\n",
    "print(\"reviewers shape:\", reviewers.shape)\n",
    "print(\"reviewers dtypes:\\n\", reviewers.dtypes)\n",
    "# JC Penney Products (JSON) ***(Transposed)\n",
    "products = pd.read_json(\"jcpenney_products.json\", lines=True)\n",
    "display(products.head(1).T)\n",
    "print(\"products shape:\", products.shape)\n",
    "print(\"products dtypes:\\n\", products.dtypes)\n",
    "# Products (CSV)\n",
    "products_csv = pd.read_csv(\"products.csv\")\n",
    "display(products_csv.head())\n",
    "print(\"products_csv shape:\", products_csv.shape)\n",
    "print(\"products_csv dtypes:\\n\", products_csv.dtypes)\n",
    "print(\"products_csv missing values:\\n\", products_csv.isna().sum())\n",
    "# Reviews (CSV)\n",
    "reviews_csv = pd.read_csv(\"reviews.csv\")\n",
    "display(reviews_csv.head())\n",
    "print(\"reviews_csv shape:\", reviews_csv.shape)\n",
    "print(\"reviews_csv dtypes:\\n\", reviews_csv.dtypes)\n",
    "# Users (CSV)\n",
    "users_csv = pd.read_csv(\"users.csv\")\n",
    "display(users_csv.head())\n",
    "print(\"users_csv shape:\", users_csv.shape)\n",
    "print(\"users_csv dtypes:\\n\", users_csv.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "For the above step, i have loaded all the five files into a pandas dataframe. I have inspected the data structure, and column types.\n",
    "Below are the observations from the data inspection.\n",
    "\n",
    "**jcpenney_reviewers.json:**  \n",
    "Contains 5,000 entries and 4 columns. The 'Reviewed' column contains empty lists ([]), indicating some users did not leave a comment. The date column is stored as an object and I will convert it to a proper datetime format to be able to calculate age from it.\n",
    "\n",
    "**jcpenney_products.json:**  \n",
    "Contains 7,982 entries and 15 columns. Some columns such as 'list_price' and 'sale_price' are stored as objects and I will converted to numeric values. The 'category_tree' column has three different categories that I will need to be separate into distinct columns.\n",
    "\n",
    "**products.csv:**  \n",
    "Contains 7,982 entries and 6 columns. Columns are uploaded correctly, but some values are missing. The 'price' column is missing 2,166 values which is approximately 27% of the price data, and the 'description' column is missing 543 values which is approximately 7% of the description data. \n",
    "\n",
    "**reviews.csv:**  \n",
    "Contains 39,063 entries and 4 columns. The columns are uploaded correctly, with the 'score' column stored as an integer.\n",
    "\n",
    "**users.csv:**  \n",
    "Contains 5,000 entries and 3 columns. The 'DOB' field should be converted to datetime to allow for calculation of age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null reviews before: 971\n",
      "Number of null reviews after: 971\n",
      "list_price                float64\n",
      "sale_price                float64\n",
      "average_product_rating    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning and preparation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Reviewers (jcpenney_reviewers.json)\n",
    "# Load the data\n",
    "reviewers = pd.read_json(\"jcpenney_reviewers.json\", lines=True)\n",
    "# Count empty lists in Reviewed \n",
    "null_reviews = reviewers[\"Reviewed\"].apply(lambda x: isinstance(x, list) and len(x) == 0).sum()\n",
    "print(\"Number of null reviews before:\", null_reviews)\n",
    "# Note: The empty lists are 971, approximately 19% of the total list; instead of dropping I will replace [] with NaN\n",
    "reviewers[\"Reviewed\"] = reviewers[\"Reviewed\"].apply(lambda x: np.nan if x == [] else x)\n",
    "print(\"Number of null reviews after:\", reviewers[\"Reviewed\"].isna().sum())\n",
    "# Convert lists to strings in Reviewed\n",
    "reviewers[\"Reviewed\"] = reviewers[\"Reviewed\"].apply(lambda x: \",\".join(x) if isinstance(x, list) else x)\n",
    "# Convert DOB to datetime\n",
    "reviewers.DOB = pd.to_datetime(reviewers.DOB, errors=\"coerce\", dayfirst=True)\n",
    "# Save to a csv file\n",
    "reviewers.to_csv(\"jcpenney_reviewers_clean.csv\", index=False)\n",
    "reviewers_clean = pd.read_csv(\"jcpenney_reviewers_clean.csv\")\n",
    "\n",
    "# Products (jcpenney_products.json)\n",
    "# Load the data\n",
    "products = pd.read_json(\"jcpenney_products.json\", lines=True)\n",
    "# Convert list_price, sale_price and average_product_rating columns to numeric\n",
    "products.list_price = pd.to_numeric(products.list_price, errors=\"coerce\")\n",
    "products.sale_price = pd.to_numeric(products.sale_price, errors=\"coerce\")\n",
    "products.average_product_rating = pd.to_numeric(products.average_product_rating, errors=\"coerce\")\n",
    "# Split category_tree into 3 parts and delete the category_tree column\n",
    "if \"category_tree\" in products.columns:\n",
    "    categories = products.category_tree.astype(\"string\").str.split(\"|\", n=2, expand=True)\n",
    "    categories = categories.rename(columns={0: \"category_1\", 1: \"category_2\", 2: \"category_3\"})\n",
    "    products = pd.concat([products.drop(columns=[\"category_tree\"]), categories], axis=1)\n",
    "# Extract User and Review from Reviews list, then drop Reviews column\n",
    "products[\"User\"] = products[\"Reviews\"].apply(lambda x: x[0][\"User\"] if isinstance(x, list) and len(x) > 0 else None)\n",
    "products[\"Review\"] = products[\"Reviews\"].apply(lambda x: x[0][\"Review\"] if isinstance(x, list) and len(x) > 0 else None)\n",
    "products = products.drop(columns=\"Reviews\")\n",
    "# Check, save, reload to verify\n",
    "products.to_csv(\"jcpenney_products_clean.csv\", index=False)\n",
    "products_clean = pd.read_csv(\"jcpenney_products_clean.csv\")\n",
    "print(products_clean.dtypes[[\"list_price\",\"sale_price\",\"average_product_rating\"]])\n",
    "\n",
    "# Products CSV (products.csv)\n",
    "# Load the data\n",
    "products_csv = pd.read_csv(\"products.csv\")\n",
    "# Ensure price and av_score are numeric\n",
    "products_csv.Price = pd.to_numeric(products_csv.Price, errors=\"coerce\")\n",
    "products_csv.Av_Score = pd.to_numeric(products_csv.Av_Score, errors=\"coerce\")\n",
    "# Fill Description/SKU; Price with median\n",
    "products_csv[\"Description\"] = products_csv[\"Description\"].fillna(\"No description available\")\n",
    "products_csv[\"SKU\"] = products_csv[\"SKU\"].fillna(\"Unknown SKU\")\n",
    "products_csv[\"Price\"] = products_csv[\"Price\"].fillna(products_csv[\"Price\"].median())\n",
    "# Check tail, save, reload\n",
    "products_csv.to_csv(\"products_csv_clean.csv\", index=True)\n",
    "products_csv_clean = pd.read_csv(\"products_csv_clean.csv\", index_col=0)\n",
    "\n",
    "# Reviews CSV (reviews.csv)\n",
    "# Load the data\n",
    "reviews_csv = pd.read_csv(\"reviews.csv\")\n",
    "# Ensure score is numeric\n",
    "reviews_csv.Score = pd.to_numeric(reviews_csv.Score, errors=\"coerce\")\n",
    "# Save & reload\n",
    "reviews_csv.to_csv(\"reviews_csv_clean.csv\", index=True)\n",
    "reviews_csv_clean = pd.read_csv(\"reviews_csv_clean.csv\", index_col=0)\n",
    "\n",
    "# Users CSV (users.csv)\n",
    "# Load the data\n",
    "users_csv = pd.read_csv(\"users.csv\")\n",
    "# Convert DOB to datetime then to string\n",
    "users_csv.DOB = pd.to_datetime(users_csv.DOB, errors=\"coerce\", dayfirst=True)\n",
    "users_csv.DOB = users_csv.DOB.dt.strftime(\"%Y-%m-%d\")\n",
    "# Save & reload\n",
    "users_csv.to_csv(\"users_csv_clean.csv\", index=True)\n",
    "users_csv_clean = pd.read_csv(\"users_csv_clean.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments \n",
    "\n",
    "As shown above, I have cleaned and prepared all the datasets. \n",
    "\n",
    "The main goal was to make sure each dataset was ready for merging and further analysis. I focused on correcting the data types, fixing missing values, and restructuring columns where needed based on the earlier observations.\n",
    "\n",
    "I have now addressed all the issues noted during the inspection stage, such as converting price and date columns into the correct formats, replacing empty lists with NaN values, and filling in missing product details. \n",
    "\n",
    "I identified the key columns that will allow me to link the datasets together later in the analysis: unique_id and username\n",
    "With these changes, the data is now consistent, clean, and ready for merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the data into one data file that i can use for my analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataset shape: (39114, 34)\n",
      "Final master dataset shape: (39114, 23)\n"
     ]
    }
   ],
   "source": [
    "# Data merging\n",
    "# Combine all cleaned datasets and prepare a unique, analysis-ready master file.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "# Load cleaned datasets and renaming them to avoid confusion\n",
    "revwrs = pd.read_csv(\"jcpenney_reviewers_clean.csv\")\n",
    "prod_json = pd.read_csv(\"jcpenney_products_clean.csv\")\n",
    "prod_csv = pd.read_csv(\"products_csv_clean.csv\")\n",
    "reviews = pd.read_csv(\"reviews_csv_clean.csv\")\n",
    "users = pd.read_csv(\"users_csv_clean.csv\")\n",
    "# Standardize key column names\n",
    "# Use 'uniq_id' to connect product-related datasets\n",
    "# Use 'Username' to connect reviewer/user-related datasets\n",
    "prod_csv.rename(columns={\"Uniq_id\": \"uniq_id\"}, inplace=True)\n",
    "reviews.rename(columns={\"Uniq_id\": \"uniq_id\"}, inplace=True)\n",
    "# Confirm required columns exist\n",
    "assert \"uniq_id\" in reviews.columns and \"Username\" in reviews.columns\n",
    "assert \"uniq_id\" in prod_csv.columns\n",
    "assert \"uniq_id\" in prod_json.columns\n",
    "assert \"Username\" in users.columns and \"Username\" in revwrs.columns\n",
    "# Merge datasets\n",
    "# Start with the reviews file (contains both uniq_id and Username)\n",
    "master = reviews.copy()\n",
    "# Merge products CSV (uniq_id)\n",
    "master = master.merge(prod_csv, on=\"uniq_id\", how=\"left\")\n",
    "# Merge products JSON (uniq_id)\n",
    "master = master.merge(prod_json, on=\"uniq_id\", how=\"left\", suffixes=(\"\", \"_json\"))\n",
    "# Merge users (Username)\n",
    "master = master.merge(users, on=\"Username\", how=\"left\", suffixes=(\"\", \"_user\"))\n",
    "# Merge reviewers (Username)\n",
    "master = master.merge(revwrs, on=\"Username\", how=\"left\", suffixes=(\"\", \"_reviewer\"))\n",
    "# Check merged structure\n",
    "print(\"Master dataset shape:\", master.shape)\n",
    "# Save full master dataset\n",
    "master.to_csv(\"jcpenney_master_dataset_full.csv\", index=False)\n",
    "# Create trimmed version with unique columns\n",
    "master = pd.read_csv(\"jcpenney_master_dataset_full.csv\")\n",
    "# Select key columns for analysis\n",
    "master_unique = master[[\n",
    "    \"Username\", \"DOB\", \"State\", \"uniq_id\", \"sku\", \"name_title\", \"description\", \"brand\",\n",
    "    \"category\", \"category_1\", \"category_2\", \"category_3\", \"list_price\", \"sale_price\",\n",
    "    \"product_url\", \"product_image_urls\", \"total_number_reviews\", \"Reviewed\",\n",
    "    \"Bought With\", \"average_product_rating\", \"Score\", \"Review\"]].copy()\n",
    "# Add 'Age' column from DOB\n",
    "master_unique[\"DOB\"] = pd.to_datetime(master_unique[\"DOB\"], errors=\"coerce\")\n",
    "today = pd.Timestamp(datetime.now().date())\n",
    "# Determine whether birthdays have passed this year\n",
    "birthday_passed = (\n",
    "    (master_unique[\"DOB\"].dt.month < today.month) |\n",
    "    ((master_unique[\"DOB\"].dt.month == today.month) & (master_unique[\"DOB\"].dt.day <= today.day)))\n",
    "# Compute age\n",
    "master_unique[\"Age\"] = today.year - master_unique[\"DOB\"].dt.year - (~birthday_passed).astype(int)\n",
    "master_unique[\"Age\"] = master_unique[\"Age\"].astype(\"Int64\")\n",
    "# Move Age column next to DOB\n",
    "cols = master_unique.columns.tolist()\n",
    "cols.insert(cols.index(\"DOB\") + 1, cols.pop(cols.index(\"Age\")))\n",
    "master_unique = master_unique[cols]\n",
    "# Fill missing sale_price with list_price\n",
    "master_unique.fillna({'sale_price': master_unique['list_price']}, inplace=True)\n",
    "# Save cleaned master dataset\n",
    "master_unique.to_csv(\"jcpenney_master_dataset_unique.csv\", index=False)\n",
    "# Check final structure\n",
    "print(\"Final master dataset shape:\", master_unique.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "After cleaning each dataset, I merged them into a single master dataset to make analysis easier and more consistent.  \n",
    "\n",
    "The 'reviews' dataset served as the main base for merging since it contained both 'uniq_id' (for products) and 'Username' (for users and reviewers).\n",
    "Before merging, I standardized the key column names to ensure consistency, renaming 'Uniq_id' to 'uniq_id' where necessary.  \n",
    "\n",
    "After merging all datasets, I saved a complete master version and then created a smaller, refined file with only the key columns needed for analysis.\n",
    "\n",
    "I also added an **Age** column derived from 'DOB' and handled any remaining missing values (e.g., filling missing 'sale_price' values with 'list_price'). In this case, if sale_price = list_price, then the product has no discount.  \n",
    "\n",
    "The final dataset, 'jcpenney_master_dataset_unique.csv', is now clean, consistent, and ready for core analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Age value_counts (first 3 by age):\n",
      "Age\n",
      "62    901\n",
      "26    853\n",
      "72    851\n",
      "Name: count, dtype: int64\n",
      "Age group summary saved to tables/age_group_summary.csv\n",
      "Age group bar chart saved to figs/age_group_distribution.png\n",
      "Top/bottom 10 state tables saved to tables/ folder\n",
      "\n",
      "Number of unique states: 57\n",
      "State percentage table saved to tables/state_percentages_top20.csv\n",
      "Top 10 states bar chart saved to figs/top10_states_customers.png\n"
     ]
    }
   ],
   "source": [
    "# 1: Who are the company's customers? (Age & State)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Create folders for outputs\n",
    "os.makedirs(\"figs\", exist_ok=True)\n",
    "os.makedirs(\"tables\", exist_ok=True)\n",
    "# Load master dataset\n",
    "master_unique = pd.read_csv(\"jcpenney_master_dataset_unique.csv\")\n",
    "# 1) AGE ANALYSIS\n",
    "# (a) Distribution by single year of age\n",
    "age_count = master_unique[\"Age\"].value_counts().sort_values(ascending=False)\n",
    "print(\"\\nAge value_counts (first 3 by age):\")\n",
    "print(age_count.head(3))\n",
    "# (b) Create age groups\n",
    "bins   = [20, 30, 40, 50, 60, 70, 80]\n",
    "labels = [\"21–30\", \"31–40\", \"41–50\", \"51–60\", \"61–70\", \"71–80\"]\n",
    "master_unique[\"Age group\"] = pd.cut(\n",
    "    master_unique[\"Age\"],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    include_lowest=True, \n",
    "    right=True)\n",
    "# Move Age group right after Age\n",
    "cols = master_unique.columns.tolist()\n",
    "if \"Age group\" in cols and \"Age\" in cols:\n",
    "    cols.insert(cols.index(\"Age\") + 1, cols.pop(cols.index(\"Age group\")))\n",
    "    master_unique = master_unique[cols]\n",
    "# (c) Summary table: counts and percentages by age group\n",
    "age_group_counts = master_unique[\"Age group\"].value_counts().sort_values(ascending=False)\n",
    "age_group_summary = pd.DataFrame({\n",
    "    \"Count\": age_group_counts,\n",
    "    \"Percentage\": (age_group_counts / age_group_counts.sum() * 100).round(2).astype(str) + \"%\"})\n",
    "# Save age group summary to CSV\n",
    "age_group_summary.to_csv(\"tables/age_group_summary.csv\", index=True)\n",
    "print(\"Age group summary saved to tables/age_group_summary.csv\")\n",
    "# (d) Visualization: bar chart of age groups\n",
    "plt.figure(figsize=(8, 5))\n",
    "master_unique[\"Age group\"].value_counts().sort_index().plot(\n",
    "    kind=\"bar\",\n",
    "    color=\"skyblue\",\n",
    "    title=\"Customer Distribution by Age Group\",\n",
    "    edgecolor=\"black\")\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.savefig(\"figs/age_group_distribution.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Age group bar chart saved to figs/age_group_distribution.png\")\n",
    "\n",
    "# 2) STATE ANALYSIS\n",
    "# (a) Counts per state\n",
    "state_counts = master_unique[\"State\"].value_counts().sort_values(ascending=False)\n",
    "# Save state tables\n",
    "state_counts.head(10).to_csv(\"tables/top10_states.csv\")\n",
    "state_counts.tail(10).to_csv(\"tables/bottom10_states.csv\")\n",
    "print(\"Top/bottom 10 state tables saved to tables/ folder\")\n",
    "# (b) Unique states count\n",
    "num_states = master_unique[\"State\"].nunique()\n",
    "print(\"\\nNumber of unique states:\", num_states)\n",
    "# (c) Top 20 states as percentages\n",
    "state_percentages = (state_counts.head(20) / len(master_unique) * 100).round(2)\n",
    "# Save top 20 state percentages\n",
    "state_percentages.to_csv(\"tables/state_percentages_top20.csv\")\n",
    "print(\"State percentage table saved to tables/state_percentages_top20.csv\")\n",
    "# (d) Visualization: bar chart of top 10 states\n",
    "plt.figure(figsize=(12, 6))\n",
    "state_counts.head(10).plot(\n",
    "    kind=\"bar\",\n",
    "    color=\"skyblue\",\n",
    "    title=\"Top 10 States by Number of Customers\",\n",
    "    edgecolor=\"black\")\n",
    "plt.xlabel(\"State\")\n",
    "plt.ylabel(\"Number of Customers\")\n",
    "plt.savefig(\"figs/top10_states_customers.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Top 10 states bar chart saved to figs/top10_states_customers.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from the above analysis\n",
    "The age with the highest number of customers for JCPenny are ages 62, 26, and 72 with 901, 953 and 851 customers respectively. \n",
    "The age group with the highest number of customers for JCPenny is 60-70 with 20.05% and 51-60 with 19.22%. The age group with the least customers is 71-80 with 9.78% and the age group 21-30 with 13.3%.\n",
    "The state with the highest customers for JCPenny are Massachussets and Kentucky with 850 and 845 customers each respectively which contributes to approximately 2.17% and 2.16% of the total customers. The states with the least customers for JCPenny are North Carolina with 499 customers and Illinois with 541 customers. There are 57 unique states with JCPenny customers, 50 from the united states and 7 from the united states territories/non-states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tables/all_brands.csv\n",
      "Brand rating distribution saved\n",
      "Brand distribution chart saved\n",
      "Saved: tables/all_categories.csv\n",
      "Saved: tables/category_counts_by_rating_range.csv\n",
      "Saved: figs/category_counts_by_rating_range.png\n",
      "Full brand, category, and product data saved to tables/ folder\n",
      "Saved: figs/products_rating_vs_reviews.png\n"
     ]
    }
   ],
   "source": [
    "#What products perform best? i.e. which brands/categories/products are most successful\n",
    "\n",
    "#1.Brand\n",
    "#Categorize the brands according to the rate bands and plot a graph showing the distribution \n",
    "brand_ratings = master_unique.groupby(\"brand\")[\"average_product_rating\"].mean().sort_values(ascending=False)\n",
    "brand_ratings.to_csv(\"tables/all_brands.csv\")\n",
    "print(\"Saved: tables/all_brands.csv\")\n",
    "#Define bins and labels\n",
    "bins = [0, 1, 2, 3, 4, 5]\n",
    "labels = [\"0–1\", \"1.1–2\", \"2.1–3\", \"3.1–4\", \"4.1–5\"]\n",
    "brand_bins = pd.cut(brand_ratings, bins=bins, labels=labels, include_lowest=True)\n",
    "brand_counts = brand_bins.value_counts().sort_index()\n",
    "brand_counts.to_csv(\"tables/brand_counts_by_rating_range.csv\")\n",
    "brand_dist = brand_bins.value_counts().sort_index()\n",
    "brand_dist.to_csv(\"tables/brand_rating_distribution.csv\")\n",
    "print(\"Brand rating distribution saved\")\n",
    "\n",
    "brand_dist.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Brand Rating Distribution\")\n",
    "plt.xlabel(\"Average Rating Range\")\n",
    "plt.ylabel(\"Number of Brands\")\n",
    "plt.savefig(\"figs/brand_rating_distribution.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Brand distribution chart saved\")\n",
    "\n",
    "#2.Category\n",
    "#Categorize the categories according to the categories bands and plot a graph showing the distribution\n",
    "category_ratings = master_unique.groupby(\"category\")[\"average_product_rating\"].mean().sort_values(ascending=False)\n",
    "category_ratings.to_csv(\"tables/all_categories.csv\")\n",
    "print(\"Saved: tables/all_categories.csv\")\n",
    "bins = [0, 1, 2, 3, 4, 5]\n",
    "labels = [\"0–1\", \"1.1–2\", \"2.1–3\", \"3.1–4\", \"4.1–5\"]\n",
    "cat_bins = pd.cut(category_ratings, bins=bins, labels=labels, include_lowest=True)\n",
    "cat_counts = cat_bins.value_counts().sort_index()\n",
    "cat_counts.to_csv(\"tables/category_counts_by_rating_range.csv\")\n",
    "print(\"Saved: tables/category_counts_by_rating_range.csv\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "cat_counts.plot(kind=\"bar\", color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Number of Categories by Average Rating Range\")\n",
    "plt.xlabel(\"Average Rating Range\")\n",
    "plt.ylabel(\"Number of Categories\")\n",
    "plt.savefig(\"figs/category_counts_by_rating_range.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: figs/category_counts_by_rating_range.png\")\n",
    "\n",
    "#3.Products by average ratings and number of reviews\n",
    "top_products = (master_unique.groupby(\"name_title\").agg({\"average_product_rating\": \"mean\",\"total_number_reviews\": \"sum\"})\n",
    "    .sort_values(by=[\"average_product_rating\", \"total_number_reviews\"], ascending=False))\n",
    "top_products.to_csv(\"tables/all_products.csv\")\n",
    "print(\"Full brand, category, and product data saved to tables/ folder\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(\n",
    "    top_products[\"total_number_reviews\"],\n",
    "    top_products[\"average_product_rating\"],\n",
    "    alpha=0.6,\n",
    "    color=\"skyblue\",       \n",
    "    edgecolors=\"black\")\n",
    "plt.title(\"Products: Average Rating vs Total Number of Reviews\")\n",
    "plt.xlabel(\"Total Number of Reviews (Popularity)\")\n",
    "plt.ylabel(\"Average Product Rating (Quality)\")\n",
    "plt.grid(axis=\"both\", alpha=0.3)\n",
    "plt.savefig(\"figs/products_rating_vs_reviews.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: figs/products_rating_vs_reviews.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most brands and categories have average ratings between 2.1–3 and 3.1–4.\n",
    "Only a few brands, like Work King and Nostalgia, have perfect scores, while others such as Young Land and Hello Kitty rate lowest.\n",
    "Popular categories include windows and comfort sneakers, while areas like health & wellness get lower reviews.\n",
    "Most products have fewer than 200 reviews, and only a few are both highly rated and popular.\n",
    "Some items sell well but get lower ratings, suggesting possible quality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figs/discount_vs_reviews.png\n",
      "Correlation between discount and sales (reviews): -0.03\n"
     ]
    }
   ],
   "source": [
    "#Are discounts driving sales or satisfaction? i.e. whether the discounts impact ratings\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Load data\n",
    "master_unique = pd.read_csv(\"jcpenney_master_dataset_unique.csv\")\n",
    "# Create discount column\n",
    "master_unique[\"Discount_%\"] = round(\n",
    "    ((master_unique[\"list_price\"] - master_unique[\"sale_price\"]) / master_unique[\"list_price\"]) * 100, 2)\n",
    "# Plot the scatter graph\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(\n",
    "    master_unique[\"Discount_%\"],\n",
    "    master_unique[\"total_number_reviews\"],\n",
    "    alpha=0.5,\n",
    "    color=\"skyblue\",     \n",
    "    edgecolors=\"black\")\n",
    "plt.title(\"Relationship Between Discount (%) and Number of Reviews (Proxy for Sales)\")\n",
    "plt.xlabel(\"Discount (%)\")\n",
    "plt.ylabel(\"Total Number of Reviews\")\n",
    "plt.savefig(\"figs/discount_vs_reviews.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: figs/discount_vs_reviews.png\")\n",
    "# Find the correlation\n",
    "corr_sales = master_unique[[\"Discount_%\", \"total_number_reviews\"]].corr().iloc[0, 1]\n",
    "print(f\"Correlation between discount and sales (reviews): {corr_sales:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from the above analysis\n",
    "\n",
    "The correlation between dicounts and sales (reviews) is -0.03 which is approximately 0. This suggests that bigger discounts do not have any impact on sales. JCPenney might need to focus on product quality or marketing instead of just lowering prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: tables/state_satisfaction_bands.csv\n",
      "Saved: figs/state_satisfaction_bands_pie.png\n",
      "Saved: tables/age_group_satisfaction_bands.csv\n",
      "Saved: figs/age_group_satisfaction_bands_donut.png\n"
     ]
    }
   ],
   "source": [
    "#Which age-group or states have a higher satisfaction?\n",
    "bands = [0, 2, 3, 4, 5]\n",
    "labels = [\"0–2 (Low)\", \"2.1–3 (Avg)\", \"3.1–4 (Good)\", \"4.1–5 (High)\"]\n",
    "colors_blue = [\"#87CEEB\", \"#5DADE2\", \"#3498DB\", \"#2E86C1\"]\n",
    "\n",
    "# a) States → satisfaction bands\n",
    "state_satisfaction = (master_unique.groupby(\"State\")[\"average_product_rating\"].mean().round(2))\n",
    "state_band = pd.cut(state_satisfaction, bins=bands, labels=labels, include_lowest=True)\n",
    "state_band_counts = state_band.value_counts().sort_index()\n",
    "state_band_counts = state_band_counts[state_band_counts > 0]\n",
    "state_band_counts.to_csv(\"tables/state_satisfaction_bands.csv\")\n",
    "print(\"Saved: tables/state_satisfaction_bands.csv\")\n",
    "# Pie chart\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(\n",
    "    state_band_counts.values,\n",
    "    labels=state_band_counts.index,\n",
    "    autopct=\"%1.0f%%\",\n",
    "    startangle=90,\n",
    "    colors=colors_blue,\n",
    "    pctdistance=0.85,      \n",
    "    labeldistance=1.3,\n",
    "    wedgeprops={\"edgecolor\": \"white\"})\n",
    "plt.title(\"States by Satisfaction Band\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/state_satisfaction_bands_pie.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: figs/state_satisfaction_bands_pie.png\")\n",
    "\n",
    "# B) Age groups → satisfaction bands\n",
    "# Ensure Age group exists\n",
    "bands = [0, 2, 3, 4, 5]\n",
    "labels = [\"0–2 (Low)\", \"2.1–3 (Avg)\", \"3.1–4 (Good)\", \"4.1–5 (High)\"]\n",
    "age_group_rating = (master_unique.groupby(\"Age group\", observed=False)[\"average_product_rating\"].mean().round(2))\n",
    "age_band = pd.cut(age_group_rating, bins=bands, labels=labels, include_lowest=True)\n",
    "age_band_counts = age_band.value_counts().sort_index()\n",
    "age_band_counts = age_band_counts[age_band_counts > 0]\n",
    "age_band_counts.to_csv(\"tables/age_group_satisfaction_bands.csv\")\n",
    "print(\"Saved: tables/age_group_satisfaction_bands.csv\")\n",
    "\n",
    "# Donut chart\n",
    "colors_for_pie = colors_blue[:len(age_band_counts)]\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.pie(\n",
    "    age_band_counts.values,\n",
    "    labels=age_band_counts.index,\n",
    "    autopct=\"%1.0f%%\",\n",
    "    startangle=90,\n",
    "    colors=colors_blue,\n",
    "    pctdistance=0.8,\n",
    "    labeldistance=1.1,\n",
    "    wedgeprops={\"width\": 0.38, \"edgecolor\": \"white\"})\n",
    "ax.set_title(\"Age Groups by Satisfaction Band\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/age_group_satisfaction_bands_donut.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved: figs/age_group_satisfaction_bands_donut.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72% of the states fall in the “Average” satisfaction band (2.1–3), with 28% in the “Good” band (3.1–4), showing moderate satisfaction overall.\n",
    "\n",
    "All age groups lie in the “Average” band, indicating that customer satisfaction is fairly consistent across ages and locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What are customers saying?\n",
    "#Convert to lowercase and remove missing values\n",
    "reviews_text = master_unique[\"Review\"].dropna().str.lower()\n",
    "#Split words into text and count which words appear the most\n",
    "#Import counter to count how many times a word appears, import re to remove the punctuations, etc, import stopwords to remove very common English words\n",
    "from collections import Counter\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='nltk')\n",
    "#Download stopwords\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "#Define stopwords set\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "#Combine all reviews into one big string\n",
    "all_text = \" \".join(master_unique[\"Review\"].dropna().str.lower())\n",
    "#Remove punctuation and numbers\n",
    "all_text = re.sub(r\"[^a-z\\s]\", \"\", all_text)\n",
    "#Split into words and filter out stopwords\n",
    "filtered_words = [word for word in all_text.split() if word not in stop_words]\n",
    "#Count most common words\n",
    "word_counts = Counter(filtered_words)\n",
    "\n",
    "#Visualize it\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(filtered_words))\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"What Customers Are Saying\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figs/customer_reviews_wordcloud.png\", dpi=300)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from the above analysis:\n",
    "\n",
    "The most common words in customer reviews include love, color, fit, great, and shoe. This shows that customers mostly talk about product appearance, comfort, and satisfaction. The frequent use of positive words like love and great suggests that most reviews are generally positive, though customers also focus heavily on fit and style details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique users: 4993\n",
      "Average reviews per user: 7.83\n",
      "Most active user wrote 68 reviews\n"
     ]
    }
   ],
   "source": [
    "#How loyal or active are users?\n",
    "# Count number of reviews per user\n",
    "user_activity = master_unique[\"Username\"].value_counts()\n",
    "#Plot the graph\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(user_activity, bins=20, color=\"skyblue\", edgecolor=\"black\")\n",
    "plt.title(\"Distribution of User Activity (Number of Reviews per User)\")\n",
    "plt.xlabel(\"Number of Reviews Written\")\n",
    "plt.ylabel(\"Number of Users\")\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.savefig(\"figs/user_activity_distribution.png\", dpi=300)\n",
    "plt.close()\n",
    "total_users = len(user_activity)\n",
    "avg_reviews = user_activity.mean()\n",
    "max_reviews = user_activity.max()\n",
    "\n",
    "print(f\"Total unique users: {total_users}\")\n",
    "print(f\"Average reviews per user: {avg_reviews:.2f}\")\n",
    "print(f\"Most active user wrote {max_reviews} reviews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations from the analysis above:\n",
    "\n",
    "Total unique users are 4993 and the average reviews per user is 7.83. And most active user wrote 68 reviews. Most users wrote fewer than 10 reviews, with only a small number posting more. This shows that while many customers engage occasionally, only a few are highly active reviewers. The user with 68 reviews is an outlier in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
